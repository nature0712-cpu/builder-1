# 프로젝트 개요: 동물상 테스트 사이트

이 프로젝트는 Google Teachable Machine 모델을 활용하여 사용자의 얼굴이 어떤 동물(개, 고양이, 토끼 등)과 닮았는지 예측하는 웹사이트입니다. 웹캠을 통해 사용자의 이미지를 캡처하고, 이를 미리 훈련된 머신러닝 모델에 입력하여 결과를 화면에 표시합니다.

## 스타일, 디자인 및 기능

### 초기 버전 (현재까지 구현된 내용)
- 기본적인 HTML, CSS, JavaScript 파일 구조.
- .gitignore 파일 추가.

### 현재 구현될 기능 (동물상 테스트 사이트)
- **사용자 인터페이스:**
    - 웹캠 피드를 표시할 영역.
    - 모델 로딩 상태 및 예측 결과를 표시할 영역.
    - 시작/정지 버튼 (필요시).
- **머신러닝 모델 통합:**
    - Teachable Machine 모델을 웹에서 로드.
    - TensorFlow.js 라이브러리 활용.
- **웹캠 접근:**
    - 사용자의 웹캠에 접근하여 비디오 스트림을 캡처.
- **실시간 예측:**
    - 웹캠 피드에서 실시간으로 이미지를 모델에 입력하여 동물상 예측.
    - 예측된 동물 유형과 신뢰도(확률)를 화면에 표시.
- **반응형 디자인:**
    - 다양한 화면 크기(모바일, 데스크톱)에서 잘 작동하도록 기본적인 반응형 스타일 적용.

## 현재 작업 계획 및 단계

1.  **`index.html` 업데이트:**
    *   기본 HTML 구조를 정의합니다.
    *   Teachable Machine 및 TensorFlow.js 라이브러리를 CDN에서 로드합니다.
    *   웹캠 비디오 스트림을 표시할 `<video>` 요소를 추가합니다.
    *   예측 결과(동물 유형, 신뢰도)를 표시할 `<div>` 요소를 추가합니다.
    *   시작/정지 버튼을 추가합니다.
2.  **`style.css` 업데이트:**
    *   전반적인 레이아웃 및 컴포넌트(비디오 영역, 결과 영역, 버튼 등)에 대한 기본 스타일을 추가합니다.
    *   모바일 반응형 디자인을 위한 미디어 쿼리를 포함합니다.
3.  **`main.js` 업데이트:**
    *   Teachable Machine 모델을 로드하는 함수를 구현합니다.
    *   웹캠 스트림을 가져와 `<video>` 요소에 연결하는 함수를 구현합니다.
    *   웹캠 피드에서 이미지를 캡처하여 모델에 입력하고 예측을 실행하는 로직을 구현합니다.
    *   예측 결과를 파싱하여 HTML 요소에 표시하는 함수를 구현합니다.
    *   페이지 로드 시 모델 로딩 및 웹캠 시작 로직을 초기화합니다.
    *   모델 URL은 사용자가 제공한 `https://teachablemachine.withgoogle.com/models/z7ub4M7Y0/`를 기반으로 `model.json`을 사용한다고 가정하고, 나중에 필요시 사용자에게 확인을 요청합니다.
4.  **`.idx/mcp.json` 업데이트:** Firebase Studio 환경에 맞게 `mcpServers` 설정을 추가하여 웹 프로젝트 실행을 지원합니다. (이미 이전에 추가되었을 수 있으므로 확인 후 진행)
